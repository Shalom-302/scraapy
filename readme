
-----

# üì∞ Scraapy ‚Äî Dashboard de Veille d'Actualit√©s avec Streamlit & IA Avanc√©e

> Scraapy est d√©sormais une application robuste et intelligente, con√ßue pour transformer la simple consultation d'actualit√©s en une veille strat√©gique approfondie. Gr√¢ce √† un workflow avanc√© propuls√© par **LangGraph**, elle extrait, analyse et synth√©tise des informations cruciales en temps r√©el, offrant des rapports de veille personnalis√©s.

-----

## üéØ Fonctionnalit√©s Cl√©s :

  * **üîé Recherche Avanc√©e :** Utilise [Tavily API](https://tavily.com) pour une recherche d'actualit√©s pertinente.
  * **üß† Intelligence Artificielle Avanc√©e :** Int√®gre les **grands mod√®les de langage (LLM) de DeepSeek** pour des capacit√©s d'analyse textuelle de pointe.
  * **üîó Workflows Complexes avec LangGraph :** Orchestre des processus de veille sophistiqu√©s, incluant la recherche, le scraping de contenu, le r√©sum√©, et l'extraction d'insights, gr√¢ce √† un pipeline multi-agents dynamique.
  * **üìä Rapports de Veille Structur√©s :** G√©n√®re des rapports concis et pertinents, incluant des r√©sum√©s d'articles, des tendances cl√©s, des entit√©s identifi√©es et des points d'action.
  * **üõ†Ô∏è Observabilit√© Compl√®te avec LangSmith :** Permet un d√©bogage, une √©valuation et une surveillance approfondie de chaque √©tape du workflow IA.
  * **‚ö° Mise en Cache Intelligente :** Utilise `@st.cache_data` pour optimiser les performances des appels externes et r√©duire les co√ªts.
  * **üåê Interface Intuitive :** Construit avec [Streamlit](https://streamlit.io) pour une exp√©rience utilisateur rapide et interactive.
  * **üóÇÔ∏è Filtres de Temps Dynamiques :** Permet de cibler les actualit√©s "Aujourd‚Äôhui", "Hier" ou "Cette semaine".

-----

## üß± Stack Technologique

  * `streamlit` ‚Äî Frontend r√©actif pour une interface utilisateur interactive.
  * `langchain-google-genai` (ou `langchain-community` pour DeepSeek) ‚Äî Int√©gration des LLM (initialement Google Gemini, d√©sormais **DeepSeek**).
  * `langgraph` ‚Äî Framework pour la cr√©ation de workflows d'agents IA complexes et cycliques.
  * `tavily-python` ‚Äî Client officiel Tavily pour la recherche d‚Äôactualit√©s cibl√©e.
  * `trafilatura` ‚Äî Biblioth√®que puissante pour l'extraction de contenu textuel propre √† partir d'URLs.
  * `pydantic` ‚Äî Validation et gestion des structures de donn√©es (pour les insights).
  * `python-dotenv` ‚Äî Gestion s√©curis√©e des cl√©s API et variables d'environnement.
  * `pandas` ‚Äî Outil d'analyse de donn√©es pour des visualisations simples.
  * `langsmith` (via `langchain`) ‚Äî Plateforme d'observabilit√© et d'√©valuation pour les applications bas√©es sur les LLM.

-----

## üõ†Ô∏è Installation

### 1\. Cloner le d√©p√¥t

```bash
git clone https://github.com/Shalom-302/scraapy.git
cd scraapy
```

### 2\. Cr√©er et activer un environnement virtuel

```bash
python -m venv .venv
source .venv/bin/activate # Sur macOS/Linux
# Ou .venv\Scripts\activate # Sur Windows
```

### 3\. Installer les d√©pendances

```bash
pip install -r requirements.txt
```

> **Exemple de contenu pour `requirements.txt` (Assurez-vous que toutes ces d√©pendances sont pr√©sentes) :**

```txt
streamlit
pandas
python-dotenv
tavily-python
langchain-google-genai # Si vous utilisez Gemini, sinon passez directement √† langchain-community
langchain-community # Pour DeepSeek et d'autres mod√®les/outils
langchain-core # Composants de base de LangChain
langgraph
trafilatura
unstructured # Pour le scraping, Trafilatura est souvent pr√©f√©r√© mais cela peut √™tre utile
pydantic # Pour les mod√®les de donn√©es
```

### 4\. Configurer les cl√©s API

Cr√©ez un fichier `.env` √† la racine de votre projet avec les cl√©s API n√©cessaires :

```env
# Cl√© pour la recherche d'actualit√©s avec Tavily
TAVILY_API_KEY="votre_cl√©_tavily_ici"

# Cl√© pour le mod√®le d'IA DeepSeek (ou autre LLM comme Gemini si pr√©f√©r√©)
# Assurez-vous que cette cl√© correspond au LLM utilis√© dans backend_scraapy.py
DEEPSEEK_API_KEY="votre_cl√©_deepseek_ici"
# Ou si vous revenez √† Gemini : GOOGLE_API_KEY="votre_cl√©_gemini_ici"

# Configuration pour LangSmith (Observabilit√© et D√©bogage)
LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT="https://api.smith.langchain.com"
LANGCHAIN_API_KEY="votre_cl√©_langsmith_ici" # C'est la cl√© que LangSmith attend
LANGCHAIN_PROJECT="" # Nom de votre projet dans LangSmith (visible dans l'interface)
```

üîë **O√π obtenir vos cl√©s :**

  * **Tavily :** [https://tavily.com](https://tavily.com)
  * **DeepSeek :** [https://platform.deepseek.com/api\_keys](https://platform.deepseek.com/api_keys)
  * **Google Gemini :** [https://aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey) (si vous choisissez de l'utiliser)
  * **LangSmith :** [https://smith.langchain.com/settings](https://smith.langchain.com/settings)

-----

## ‚ñ∂Ô∏è Lancer l'application

Votre application est maintenant divis√©e en deux modules : `scraap.py` (la logique LangGraph) et `main.py` (l'interface Streamlit).

```bash
streamlit run main.py
```

Puis ouvrez le lien local propos√© par Streamlit dans votre navigateur (par d√©faut [http://localhost:8501](https://www.google.com/search?q=http://localhost:8501)).

-----

### **Conseils pour le D√©veloppement et le D√©bogage :**

  * **LangSmith est votre meilleur ami \!** Visitez votre projet LangSmith √† l'adresse indiqu√©e dans `LANGCHAIN_PROJECT` apr√®s chaque ex√©cution. Vous pourrez y voir le d√©roulement d√©taill√© de chaque appel LLM, l'√©tat de votre graphe LangGraph, et identifier pr√©cis√©ment o√π les probl√®mes (comme les quotas API) surviennent.
  * **Surveillez le terminal :** Gardez toujours un ≈ìil sur le terminal o√π vous lancez l'application pour les messages d'erreur et les `print` que vous avez ajout√©s.

-----
